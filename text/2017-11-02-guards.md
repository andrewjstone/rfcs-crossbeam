# Summary

Replace `Scope` with `Guard`.

# Motivation

In the [Atomic API RFC](https://github.com/crossbeam-rs/rfcs/blob/master/text/2017-05-02-atomic-api.md#scopes-or-guards)
we decided to model pinning using scopes instead of guards. The rationale was that
the previous implementation of pinning using guards was unsound and it was not
entirely obvious how to fix the problem.

The issue with guards is that they hold a pointer/reference to thread-local data,
but they're not constrained by a lifetime (like scopes are), and thus they may outlive
the referenced thread-local data. An example demonstrating that was presented in the
aforementioned RFC.

The key to solving the problem is the following. Instead of *constraining* the life of
a scope/guard so that it doesn't live longer than thread-local data, we can *extend* the
life of thread-local data by using reference counting.
If the thread-local data is reference-counted, a guard can safely hold a reference to
the data for an arbitrarily long time.

# Detailed design

There is already a [PR ready for review](https://github.com/crossbeam-rs/crossbeam-epoch/pull/31)
that replaces scopes with guards.

## The interface

```rust
// The guard type.
pub struct Guard { ... }

// This interface is no different than the one of `Scope`.
impl Guard {
    pub unsafe fn defer<F, R>(&self, f: F)
    where
        F: FnOnce() -> R + Send;

    pub fn flush(&self);
}

// These two functions don't take a closure anymore - they return a guard instead.
pub fn pin() -> Guard;
pub unsafe fn unprotected() -> Guard;

// Methods now take a `&Guard` instead of a `&Scope`.
impl<T> Atomic<T> {
    pub fn compare_and_set<'g, O>(
        &self,
        current: Ptr<T>,
        new: Ptr<T>,
        ord: O,
        _: &'g Guard,
    ) -> Result<(), Ptr<'g, T>>
    where
        O: CompareAndSetOrdering;

    // The same applies to other methods...
}
```

## How reference counting works

Each thread participating in epoch-based garbage collection has some heap-allocated
data associated with it (in struct `Local`). All such `Local`s are connected into a
linked list and the head pointer of that list is held in the global data (in struct `Global`).
`Global` also holds the global epoch and the global garbage queue.

Each `Local` holds a `ManuallyDrop<Arc<Global>>`, thus keeping the garbage collector in
which it resides alive.
Similarly, each `Handle` and each `Guard` keeps a pointer to the `Local` associated with it.
Handles and guards are counted using fields `handle_count` and `guard_count` inside `Local`.
When both counts reach zero, the `Arc<Global>` inside `Local` is immediately dropped
(using `ManuallyDrop::drop`), and the heap-allocated `Local` is then marked as deleted.
If that `Local` was holding the last reference to the `Global`, then the
`Global` is destroyed as well.

## Changes to the `Collector` interface

### Should `Handle` be `Send`?

If we allow `Handle`s to be `Send`, the following code will compile:

```rust
let c = Collector::new();
let h = c.handle();
let guard = h.pin();

thread::spawn(move || {
    let guard = h.pin();
});
```

This is a suspicious, although not necessarily a *wrong* piece of code. However, if we
allowed this to be possible, `guard_count` would have to be an atomic integer, and
atomic operations on the counter would unnecessarily slow down pinning.

For that reason, `Handle` will not be `Send`.

Note that, currently, `Handle::clone` creates a brand new handle that can be passed to
another thread (see [PR #26](https://github.com/crossbeam-rs/crossbeam-epoch/pull/26)),
but with non-`Send` handles that cloning behavior is not very useful anymore.

### Accessing the default handle

Moreover, we'been having difficulties finding a satisfying signature for the
`default_handle` method (see [PR #28](https://github.com/crossbeam-rs/crossbeam-epoch/pull/28)).
The dilemma is whether we should have:

1. Unsafe function `default_handle` returning a `&'static Handle`.
2. Safe function `with_default_handle` taking a closure (similar to `LocalKey::with`).
   This is slightly unergonomic.
3. Safe function `default_handle` that uses reference counting (`Arc`) to return a
   reference to the default handle. This would be very similar to the behavior of
   `std::thread::current()`. The main problem is that cloning an `Arc` would be slow.

But if handles are not `Send`, a fourth option emerges:

4. Same as the third option, but have internal reference counting using `Rc` instead of `Arc`.
   This greatly reduces the incurred performance costs.

### The new interface

First, `Handle::clone` will be changed so that it increments the internal reference count
(`handle_count`) and returns a new reference to the same handle (just like
`Thread::clone` returns a new reference to the same thread).

Second, `default_handle` will be implemented like this:

```rust
lazy_static! {
    static ref COLLECTOR: Collector = Collector::new();
}

thread_local! {
    static HANDLE: Handle = COLLECTOR.handle();
}

pub fn default_handle() -> Handle {
    HANDLE.with(|handle| handle.clone())
}
```

With this interface accessing the default handle is safe and ergonomic, but
there is some associated cost of reference counting. Fortunately, the cost
is small enough to be forgivable, as will be demonstrated by benchmarks...

## Benchmarks

Here's a trivial benchmark that assures that guards don't bring
a performance regression (or at least not a significant one):

```rust
// Before: pinning with scopes.
#[bench]
fn pin_empty(b: &mut Bencher) {
    b.iter(|| epoch::pin(|_| ()));
}

// After: pinning with guards.
#[bench]
fn pin_empty(b: &mut Bencher) {
    b.iter(|| epoch::pin());
}
```

Both before and after benchmarks show the same numbers:

```
test pin_empty ... bench:          12 ns/iter (+/- 0)
```

Now let's see how pinning using `default_handle` fares:

```rust
#[bench]
fn default_handle_pin(b: &mut Bencher) {
    b.iter(|| epoch::default_handle().pin());
}
```

Result:

```
test default_handle_pin ... bench:          13 ns/iter (+/- 0)
```

As can be seen from the results, pinning with `epoch::pin()` is a little bit
faster than with `epoch::default_handle().pin()` (12 ns and 13 ns).
This is due to the overhead of reference counting, but the difference is small
enough that it won't matter in practical situations.

# Drawbacks

In theory, pinning with scopes has the potential to be a little bit faster.

Scopes have a more rigid structure - they're perfectly nested, as can be seen in the
following example:

```rust
epoch::pin(|first| {
    epoch::pin(|second| {
        // `second` is created after `first`.
        // ..
        // `second` dies before `first`.
    })
})
```

On the other hand, guards can be created, moved, and dropped at arbitrary points in time:

```rust
let a = epoch::pin(); // The first guard is created.
let b = epoch::pin(); // The second guard is created.

let c = a; // The first guard is moved.

drop(c); // The first guard is dropped.
drop(b); // The second guard is dropped.
```

When unpinning the thread, both scopes and guards decrement a counter that
keeps track of how many levels of nesting there are. However, when unpinning,
scopes already know whether the counter will become zero, while guards don't.
With scopes, the value of the counter cannot be different from the one that was
encountered when the scope was created.

Long story short: guards have one additional branch when unpinning.
But the impact of that branch on performance seems to be minimal.

# Alternatives

1. Keep `Scope` without introducing `Guard`.
2. Provide both `Scope` and `Guard` at the same time.

# Unresolved questions

1. Do we want a public `default_collector()` function as well?
2. Do we need a `Handle::collector()` accessor?
