# Summary

Replace `Scope` with `Guard`.

# Motivation

In the [Atomic API RFC](https://github.com/crossbeam-rs/rfcs/blob/master/text/2017-05-02-atomic-api.md#scopes-or-guards)
we decided to model pinning using scopes instead of guards. The rationale was that
the previous implementation of pinning using guards was unsound and it was not
entirely obvious how to fix the problem.

The issue with guards is that they hold a pointer/reference to thread-local data,
but they're not constrained by a lifetime (like scopes are), and thus they may outlive
the referenced thread-local data. An example demonstrating that was presented in the
aforementioned RFC.

The key to solving the problem is the following. Instead of *constraining* the life of
a scope/guard so that it doesn't live longer than thread-local data, we can *extend* the
life of thread-local data by using reference counting.
If the thread-local data is reference-counted, a guard can safely hold a reference to
the data for an arbitrarily long time.

# Detailed design

There is already a [PR ready for review](https://github.com/crossbeam-rs/crossbeam-epoch/pull/31)
that replaces scopes with guards.

## The interface

```rust
// The guard type.
pub struct Guard { ... }

// This interface is no different than the one of `Scope`.
impl Guard {
    pub unsafe fn defer<F, R>(&self, f: F)
    where
        F: FnOnce() -> R + Send;

    pub fn flush(&self);
}

// These two functions don't take a closure anymore - they return a guard instead.
pub fn pin() -> Guard;
pub unsafe fn unprotected() -> Guard;

// Methods now take a `&Guard` instead of a `&Scope`.
impl<T> Atomic<T> {
    pub fn compare_and_set<'g, O>(
        &self,
        current: Ptr<T>,
        new: Ptr<T>,
        ord: O,
        _: &'g Guard,
    ) -> Result<(), Ptr<'g, T>>
    where
        O: CompareAndSetOrdering;

    // The same applies to other methods...
}
```

## How reference counting works

Each thread participating in epoch-based garbage collection has some heap-allocated
data associated with it (in struct `Local`). All such `Local`s are connected into a
linked list and the head pointer of that list is held in the global data (in struct `Global`).
`Global` also holds the global epoch and the global garbage queue.

Each `Local` holds a `ManuallyDrop<Arc<Global>>`, thus keeping the garbage collector in
which it resides alive.
Similarly, each `Handle` and each `Guard` keeps a pointer to the `Local` associated with it.
Handles and guards are counted using fields `handle_count` and `guard_count` inside `Local`.
When both counts reach zero, the `Arc<Global>` inside `Local` is immediately dropped
(using `ManuallyDrop::drop`), and the heap-allocated `Local` is then marked as deleted.
If that `Local` was holding the last reference to the `Global`, then the
`Global` is destroyed as well.

## Changes to the `Collector` interface

If we allow `Handle`s to be `Send`, the following code will compile:

```rust
let c = Collector::new();
let h = c.handle();
let guard = h.pin();

thread::spawn(move || {
    let guard = h.pin();
});
```

This is a suspicious, although not necessarily a *wrong* piece of code. However, if we
allowed this to be possible, `guard_count` would have to be an atomic integer, and
atomic operations on the counter would unnecessarily slow down pinning.
For that reason, `Handle` will not be `Send`.

Currently, `Handle::clone` creates a brand new handle that can be passed to another thread
(see [PR #26](https://github.com/crossbeam-rs/crossbeam-epoch/pull/26)), but with
non-`Send` handles that cloning behavior is not very useful anymore.
Moreover, we haven't been able to find a satisfying signature for the `default_handle` method
(see [PR #28](https://github.com/crossbeam-rs/crossbeam-epoch/pull/28)), but with
non-`Send` handles there's an easy solution.

`Handle::clone` will be changed so that it returns a new reference to the same handle (just like
`Thread::clone` returns a new reference to the same thread).

Then we can implement `default_handle` like this:

```rust
lazy_static! {
    static ref COLLECTOR: Collector = Collector::new();
}

thread_local! {
    static HANDLE: Handle = COLLECTOR.handle();
}

pub fn default_handle() -> Handle {
    HANDLE.with(|handle| handle.clone())
}
```

This way `default_handle` bears some cost of reference counting, but it should be
forgivable, as is demonstrated by the benchmarks...

## Benchmarks

Here's a trivial benchmark that assures that guards don't bring
a peformance regression (or at least not a significant one):

```rust
// Before: pinning with scopes.
#[bench]
fn pin_empty(b: &mut Bencher) {
    b.iter(|| epoch::pin(|_| ()));
}

// After: pinning with guards.
#[bench]
fn pin_empty(b: &mut Bencher) {
    b.iter(|| epoch::pin());
}
```

Both before and after benchmarks show the same numbers:

```
test pin_empty ... bench:          12 ns/iter (+/- 0)
```

Now let's see how pinning using `default_handle` fares:

```rust
#[bench]
fn default_handle_pin(b: &mut Bencher) {
    b.iter(|| epoch::default_handle().pin());
}
```

Result:

```
test default_handle_pin ... bench:          13 ns/iter (+/- 0)
```

# Drawbacks

In theory, pinning with scopes has the potential to be a little bit faster.

Scopes have a more rigid structure - they're perfectly nested, as can be seen in the
following example:

```rust
epoch::pin(|first| {
    epoch::pin(|second| {
        // `second` is created after `first`.
        // ..
        // `second` dies before `first`.
    })
})
```

On the other hand, guards can be created, moved, and dropped at arbitrary points in time:

```rust
let a = epoch::pin(); // The first guard is created.
let b = epoch::pin(); // The second guard is created.

let c = a; // The first guard is moved.

drop(c); // The first guard is dropped.
drop(b); // The second guard is dropped.
```

When unpinning the thread, both scopes and guards decrement a counter that
keeps track of how many levels of nesting there are. However, when unpinning,
scopes already know whether the counter will become zero, while guards don't.
With scopes the value of the counter cannot be different from the one that was
encountered when the scope was created.

Long story short: guards have one additional branch when unpinning.
But the impact of that branch on performance seems to be minimal.

# Alternatives

1. Keep `Scope` without introducing `Guard`.
2. Provide both `Scope` and `Guard` at the same time.

# Unresolved questions

1. Do we want a public `default_collector()` function as well?
2. Do we need a `Handle::collector()` accessor?
